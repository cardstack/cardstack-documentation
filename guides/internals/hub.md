I know that I will get the terminology wrong in this section and I may not have the details right but I will instead list out my understanding on how the data access works and hopefully provide some "useful mental models" even if they're not 100% correct.

The Cardstack **hub** is the heart of the system and can be considered as a sort of "cache" of external datasources. So far in our development of the test-harness it may have been difficult to sepearate the nature of an "external" data source and the cache nature of the hub because of the fact that we've been dealing with a single API that responds with the entities that we have created in it via the same API. I will do my best to outline this difference below.

Firstly let's point out how the "cache" nature of a hub. This "cache" is actually an **index** of the data in the data sources. When you hit the JSON:API api for cardstack you are **never** hitting an external datasource you are just hitting the index. You will see this when you look at the middleware that the @cardstack/jsonapi package provides (middleware is a data-type that a Cardstack plugin can provide). Looking the jsonapi middleware you can see that all data access goes through the **searcher** that is injected into the constructor of the middleware. This means that the jsonapi middleware is just reading the cached index directly when a request comes in. In our test-harness we are using postgres as our index provider through the @cardstack/pgsearch package. If you open postgres you will see a documents collection that contains the data for each card as well as the tsvector which is used for the full text search part of the system.

My understanding of the data flow in the Cardstack hub is that we have **indexers** to pull data into the local cache, **searchers** to access it and **writers** that are used to push data back out to the 3rd party data source. I don't know very much about the protocol or lifecycle of this par to f the system yet as I have not had to jump into it in any major depth.
